{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Malaria Risk Stratification with Algorithmic Fairness\n",
        "\n",
        "This notebook implements the Tai & Dhaliwal (2022) wGRS+GF+POS methodology on synthetic MalariaGEN-like data to compare Ridge, LightGBM, and SVR models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "sys.path.append(str(Path('..') / 'src'))\n",
        "\n",
        "from synthetic_clinical_data import MalariaDataGenerator\n",
        "from evolutionary_models import MalariaRiskPredictor\n",
        "\n",
        "sns.set_theme(style='white', font='serif')\n",
        "plt.rcParams['figure.dpi'] = 120\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Generating synthetic clinical data (n=20,817)...')\n",
        "generator = MalariaDataGenerator()\n",
        "df = generator.generate()\n",
        "\n",
        "display(df.head())\n",
        "print(df['population'].value_counts(normalize=True).head())\n",
        "print('Case rate:', df['case'].mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictor = MalariaRiskPredictor()\n",
        "X, y, feature_names = predictor.prepare_features(df)\n",
        "groups = df['population'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test, grp_train, grp_test = train_test_split(\n",
        "    X, y, groups, test_size=0.2, stratify=groups, random_state=42\n",
        ")\n",
        "\n",
        "print('Training set:', X_train.shape)\n",
        "print('Test set:', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_results = predictor.train_ridge(X_train, y_train)\n",
        "lgb_results = predictor.train_lightgbm(X_train, y_train)\n",
        "svr_results = predictor.train_svr(X_train, y_train)\n",
        "\n",
        "def evaluate(model_name, X, y):\n",
        "    model = predictor.models[model_name]\n",
        "    scaler = predictor.scalers.get(model_name)\n",
        "    X_in = scaler.transform(X) if scaler else X\n",
        "    preds = model.predict(X_in)\n",
        "    mae = mean_absolute_error(y, preds)\n",
        "    auc = roc_auc_score(y, preds)\n",
        "    return mae, auc, preds\n",
        "\n",
        "results = {}\n",
        "for name in ['ridge', 'lightgbm', 'svr']:\n",
        "    mae, auc, preds = evaluate(name, X_test, y_test)\n",
        "    results[name] = {'mae': mae, 'auc': auc, 'preds': preds}\n",
        "\n",
        "pd.DataFrame(results).T[['mae', 'auc']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "models = list(results.keys())\n",
        "maes = [results[m]['mae'] for m in models]\n",
        "bars = ax.bar(models, maes, color=['#4C72B0', '#55A868', '#C44E52'], alpha=0.85)\n",
        "ax.set_ylabel('Mean Absolute Error')\n",
        "ax.set_title('Model Performance Comparison (Lower is Better)')\n",
        "for bar, val in zip(bars, maes):\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{val:.4f}',\n",
        "            ha='center', va='bottom')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "importance = lgb_results['feature_importance']\n",
        "top_idx = np.argsort(importance)[-10:]\n",
        "top_features = [feature_names[i] for i in top_idx]\n",
        "top_values = importance[top_idx]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "ax.barh(top_features, top_values, color='#4C72B0')\n",
        "ax.set_xlabel('Gain Importance')\n",
        "ax.set_title('Top 10 Features (LightGBM)')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_results = ridge_results['cv_results']\n",
        "alpha_values = cv_results['param_alpha'].data\n",
        "mean_scores = -cv_results['mean_test_score']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.plot(alpha_values, mean_scores, marker='o')\n",
        "ax.set_xscale('log')\n",
        "ax.set_xlabel('Ridge Alpha (log scale)')\n",
        "ax.set_ylabel('CV MAE')\n",
        "ax.set_title('Ridge Hyperparameter Comparison')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "hyper_df = pd.DataFrame({\n",
        "    'model': ['ridge', 'lightgbm', 'svr'],\n",
        "    'primary_hyperparameter': [\n",
        "        ridge_results['best_alpha'],\n",
        "        31,\n",
        "        1.0,\n",
        "    ],\n",
        "})\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "ax.bar(hyper_df['model'], hyper_df['primary_hyperparameter'], color='#8172B2')\n",
        "ax.set_ylabel('Selected Hyperparameter')\n",
        "ax.set_title('Hyperparameter Comparison (Selected Values)')\n",
        "sns.despine()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}